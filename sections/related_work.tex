%!TEX root = ../copatterns-thesis.tex
\chapter{Related Work}
\label{cha:related-work}

\section{Copatterns}
\label{sec:related_work_copatterns}
\todo{Relate to 'Unnesting of Copatterns' by Setzer et al.}

\section{Size-change Termination}
Since Idris already has a working totality checker using size-change termination\,\citep{BradyIdrisImpl13}, it would be interesting if the size-change principle could be used for determining the productivity of corecursive functions as well. The size-change principle for termination was first proposed for a strict first-order functional language (without loop constructs) by Lee, Jones, and Ben-Amram\,\citep{LeeJones01SizeChange}. The principle essentially states that if infinitely many recursive calls to a function would lead to infinite decrease in some parameter value, then the function must be terminating, since any value of an inductive type must have finite size. This last condition is of particular importance, as the size-change principle cannot in general recognize functions as being terminating if they have parameters that do not exhibit a well-founded order. Lee, Jones, and Ben-Amram present two realizations of the principle, one using automata and one using a call graph. In the graph formulation, termination is determined by identifying any recursive calls (both direct and indirect) through cycles in the call graph, and then constructing a ``size-change graph'' for each of these. The size-change graphs are then used to find out whether infinite descent in some parameter value is present. One of the limitations of this approach is that parameter values must decrease monotonically: Values cannot at any point become structurally larger, even though the total change in size in a call chain would ultimately lead a to a decreasing value. Two examples of size-change terminating functions are shown in Figure~\ref{fig:sizechange_plus_map}. In both examples, the recursive call happens on structurally smaller input.

\begin{figure}
\begin{lstlisting}[mathescape]
plus : Nat $\to$ Nat $\to$ Nat
plus Z      m = m
plus (S n') m = plus n' m

map : (a $\to$ b) $\to$ Vect n a $\to$ Vect n b
map f []        = []
map f (x :: xs) = f x :: map f xs
\end{lstlisting}
\caption{Two size-change terminating functions.}
\label{fig:sizechange_plus_map}
\end{figure}

Since its first-order formulation, the principle has been proven to be applicable to more expressive cases. Jones and Bohr\,\citep{Jones04Untyped} showed that size-change termination can be applied to the untyped lambda calculus using abstract interpretation\,\citep{Jones:1995}. A set of safe size-change graphs for a program is generated by defining evaluation rules without an environment component, thus overapproximating the number of possible values for any given variable. Given these rules, a corresponding overapproximated set of safe size-change graphs is generated for further termination analysis. Note that due to the undecidability of the halting problem, it is impossible in general to compute the exact set of safe size-change graphs for a given function call.

Following the work on the untyped lambda calculus, Sereni and Jones generalized the size-change principle to handle a higher-order functional language with user-defined data types and general recursion\,\citep{Sereni05terminationanalysis,Sereni06Phd}. Here, a termination criterion is presented which works for arbitrary control-flow graphs, and in turn is able to give an approximation of termination for both strict and lazy functional programs. A key point in this work is how different approaches to control-flow and call graph construction may influence the preciseness of the termination analysis.

All of the previously mentioned implementations of the size-change principle can only approximate termination for programs involving data which exhibits some well-founded order. Nevertheless, Avery\,\citep{Avery06} presented a formulation in which it is possible to detect size-change termination for non-well-founded data types --- in particular, this formulation is shown to work for a language with an integer type. Instead of identifying infinite descent using a well-founded partial order on parameter, as proposed by Lee at al., Avery's analysis is based on a decrease in invariants which are found to hold for each program point. The idea is that if the value of some invariant (which can involve arbitrarily many values) can be shown to decrease on every passage of a program point, then the program terminates. A simple example of a size-change terminating program in Avery's implementation is given in Figure~\ref{fig:avery_example}. The invariant for the inner loop is \texttt{n - j + i}, while the one for the outer loop is \texttt{n - i}. These cannot decrease indefinitely, and therefore the program is size-change terminating.

\begin{figure}
\begin{lstlisting}
for (i = 0; i <= n; i++) {
  for (j = 0; j-i <= n; j++);
}
return;
\end{lstlisting}
\caption{An example program involving integers written in a subset of C, which is size-change terminating in Avery's formulation.}
\label{fig:avery_example}
\end{figure}

While size-change termination for non-well-founded data could be a step towards using a size-change approach for an approximation of productivity, it is unclear which invariants one would have to infer for corecursive programs. A first attempt might emerge from the observation that any productive corecursive program cannot consume any more data than it produces. Based solely on syntax, such an analysis would quickly approach the idea behind syntactic guardedness checkers, which will be discussed in Section~\ref{sec:synt-guard}.

In more recent work, Hyvernat\,\citep{Hyvernat13} has proposed a formulation of the size-change principle for functional languages which to a certain degree solves the problem of non-monotonic decrease in parameter values. The motivation behind this work is to incorporate size-change termination into the PML language\,\cite{PMLLanguage}. Non-monotonic decrease is detected by tracking the size of a parameter throughout the entire control-flow graph, instead of merely recording whether each call in isolation leads to a decrease in some value.

The termination criterion most similar to the size-change principle predates the original article by Lee, Jones, and Ben-Amram\,\citep{LeeJones01SizeChange}. This criterion was developed by Abel for the \texttt{foetus} termination checker\,\citep{Abel98foetus}, and forms the basis of the totality checker implemented in Agda\,\citep{Norell:thesis}. Analogous to the size-change principle, Abel identifies recursive calls in a call graph and performs a termination analysis by tracking changes in parameter sizes. This initial presentation of \texttt{foetus} makes no mention of productivity for corecursive programs, although such an extension has since been presented by Altenkirch and Danielsson\,\citep{AltenkirchNAD10} (for further discussion, see Section~\ref{sec:synt-guard}).

\section{Syntactic Guardedness}
\label{sec:synt-guard}
% Telford and Turner nÃ¦vnes mere
% Hyvernat flyttes herned

Due to the duality between inductive and coinductive types, it may be compelling to imagine a productivity analysis which, dual to the size-change principle, works by identifying structurally larger values. Such a dual notion of ``size-change productivity'' is exactly the idea behind the syntactic guardedness checkers found in Idris, Agda, and Coq\,\citep{Coq:manual}. Where values become structurally smaller by pattern matching, they become structurally larger by constructor application. Therefore, the \emph{guardedness principle} states that a coinductive definition is guarded if all corecursive calls appear directly under a coinductive constructor. This has the implication that the productivity of corecursive functions can be detected by a purely syntactic check.

The guardedness principle was first proposed by Coquand\,\citep{Coquand94} has a tool for constructive reasoning about infinite objects. Coquand argues that previous coinductive proof methods rely on impredicative definitions, which he deems to be ``unsatisfactory'' for constructive reasoning. Based on Milner's work on process calculi\,\citep{Milner:1989}, Coquand defines an infinite object to be productive if a (not necessarily well-founded) computation tree can be associated with it, through an analogy between infinite proof objects and processes. This observation is then synthesized into a ``guarded induction principle''. In practice, the guarded induction principle can be used for constructive proofs through a syntactic check, which verifies that all corecursive references appear directly under a coinductive constructor.

In continuation of Coquand's efforts, Gim\'{e}nez\,\citep{Gimenez95} formalized an extension of the Calculus of Constructions\,\citep{Coquand:1988}, in which a modification of Coquand's original formulation of the guarded induction principle is provided. In particular, the guarded induction principle is modified such that it can be applied to types with second-order quantification.

The guarded induction principle described by Coquand and Gim\'{e}nez was intended to be used within a proof system (e.g. Coq) for easier reasoning about infinite objects. Confirming Coquand's own observation, Telford and Turner\,\citep{Telford98ensuringthe} argue that the guarded induction principle is too conservative in a programming setting. In their system of \emph{Elementary Strong Functional Programming} (ESFP)\,\citep{Telford97ensuringstreams,Telford98ensuringthe,Telford:jucs_6_4:ensuring_termination_in_esfp}, Telford and Turner therefore extend practical use of the guarded induction principle to detect a wider range of function as productive. They achieve this by considering guardedness more abstractly over a domain of ``guardedness levels'', such that productive corecursion is bounded by a given ``depth''. Intuitively, their system works by detecting that a program produces more elements that it consumes, i.e. that recursive references are subject to more introduction forms (constructor applications) than elimination forms (case analysis). Since any program can be higher-order, the guardedness level of a function is calculated by a ``guardedness function'',  where the guardedness levels of both bound and free variables are taken into account. As an advanced example, Telford and Turner show that the program generating the Hamming numbers (a problem first discussed by Dijkstra\,\citep{Dijkstra:1997}) is accepted as a productive program by their system.

Hyvernat\,\citep{Hyvernat13} discusses an approach similar to the idea behind the work of Telford and Turner. He proposes that productivity can be detected by counting the number of abstractions and applications in a program, respectively. Given that one does not reduce under abstractions, a function can then be considered productive if it has more abstractions than applications, since this necessarily means that the program will not diverge.

Another approach to coping with the conservative nature of the original guardedness principle is to consider alternative programming styles, making productive definitions easier to write. Following the incorporation of the guardedness condition into the Agda totality checker as described by Altenkirch and Danielsson (they attribute their approach to Abel)\,\citep{AltenkirchNAD10}, Danielsson\,\citep{Danielsson10beatingthe} described a method for working around the guardedness condition whenever it rejects a productive program. When a corecursive reference appears under a call to a function which is not a constructor, he designs an embedded domain-specific language in which said function is implemented as a constructor, making the guarded induction principle applicable. He is then able to define an interpreter for this language, such that the original program is ultimately accepted as productive. None of these steps happen automatically, but must be done manually. Although useful, Danielsson argues that efficiency is a concern, and that the best solution might be to entirely move away from using guardedness for productivity. Sized types have since been implemented in Agda.

\section{Guarded Recursion}
%Nakano
%neelk
%Atkey and McBride
%Flere papers fra Aarhus + Mogel

As presented in Section~\ref{sec:guarded-recursion}, guarded recursive type systems can be used to define necessarily productive programs. The general notion underlying guarded recursion was introduced by Nakano\,\citep{Nakano:2000}, although he does not himself use the term ``guarded recursion''. He introduces a modal typing system with recursive types, $\lambda\!\bullet\!\mu$, in which it is possible to encode provably non-diverging programs. This is achieved partly by giving a modal type to the Y-combinator (see Figure~\ref{fig:nakano_Y}), and partly by defining types such that recursive occurrences are only available in the context of a modality $\bullet$, e.g. infinite binary trees as a type $\mu X.A\times\bullet X\times\bullet X$. Nakano suggests that his system could be related to temporal logic, where the $\bullet$ modality reprensents notions of ``previous time''. Additionally, he notes that the system is not intended to be used as a type system for programming languages, but serves to widen the range of programs to which the idea of proofs-as-programs can be applied.

\begin{figure}
\[
\vdash \lambda f. (\lambda x. f (x x)) (\lambda x. f (x x)) : (\bullet X \to X) \to X
\]
\caption{The Y-combinator as derived in Nakano's $\lambda\!\bullet\!\mu$ system\,\citep{Nakano:2000}.}
\label{fig:nakano_Y}
\end{figure}

Inspired by Nakano's approach, Atkey and McBride\,\citep{Atkey:2013} present a similar typing discipline based on the simply typed lambda calculus, paving the way for a more practical use of guarded recursion. They introduce applicative programming\,\citep{Mcbride:2008} over modalities, which coupled with Nakano's fixed point combinator makes programming with modalities more accessible, and provides a more compositional system for productivity checking. Their main contribution is the introduction of clock variables into a type system with guarded recursion, such that it is possible to distinguish between values that are in the process of construction and values that are fully constructed. Fully constructed values can be identified by universal quantification over clock variables, enabling the user to extract values from the modal world of guarded recursion.

Following the work by Atkey and McBride, M\o gelberg\,\citep{Mogelberg:2014} extends the idea of a type system with guarded recursion and clock variables to a dependently typed setting. Based on work by Birkedal and M\o gelberg\,\citep{BirkedalL:sgdtuniverse-conf} and Birkedal, M\o gelberg, Schwinghammer, and St\o vring\,\citep{BirkedalL:sgdt-journal}, he models a dependently typed lambda calculus with guarded recursion and clocks using the topos of trees model. This results in an extensional type theory for reasoning about guarded recursive types. Although no intensional formulation of the model is given, it is expected that such a formulation exists.

% In extensional type theory, definitional and propositional equality is the same
Typing systems with modalities on types as introduced by Nakano has also been applied in the field of functional reactive programming. Krishnaswami\,\citep{Krishnaswami13} presents a typing system where both time leaks (depending on past values for arbitrary intervals of time) and space leaks (non-permanent memory leaks from capturing too much history) are prevented by construction. This is accomplished by typing all values with \emph{temporal recursive types}, using modalities on types to indicate the time at which a value becomes available. In the context of a global clock, programs are then evaluated according to two operational semantics: one giving the semantics for a program at the current clock tick, and one for advancing the global clock. Whenever the global clock is advanced, all values which can no longer be referenced due to time constraints are discarded from the environment, thus eliminating space leaks. Accompanying this mechanism are rules which make references to unavailable data impossible. Time leaks are prevented by unfolding all values at the moment they become available. Since Krishnaswami's approach enforces causality (that the first \emph{n} outputs only depend on the first \emph{n} input values), it can essentially be used to encode guarded recursion, at least in the simply typed formulation by Atkey and McBride. But where Atkey and McBride emphasize that clock variables localize the encoding of productivity, Krishnaswami introduces a global clock to which all programs must adhere.

\section{Sized Types}
An alternative approach to type-based totality checking is sized types. Where the intuitive abstraction of guarded recursion is time, sized types attach sizes to values at the type level. The motivation behind sized types is to express totality proofs using induction on sizes, such that the structure of the term in question can be disregarded. With size-change termination, termination proofs are constructed by ensuring that all recursive arguments happen on structurally smaller terms. Analogously, totality proofs using sized types are constructed by ensuring that all values are defined in terms of data with a structurally smaller \emph{size}.  Hence, the term ``size'' implies no specific term structure on the data involved in the totality proof.

Sized types for totality checking were first proposed by Hughes, Pareto, and Sabry\,\citep{Hughes96} for reactive systems, where each data type introduced into a program is associated with a family of sized types indicating the bounds of a value of that type. A similar idea was developed by Amadio and Coupet-Grimal\,\citep{Amadio98}, where guard conditions are introduced into the type system to ensure the productivity of coinductive data, following the work of Coquand\,\citep{Coquand94} and Gim\'{e}nez\,\citep{Gimenez95}.

Eduarde Gim\'{e}nez also presented a system for typing recursive definitions in an extension of the Calculus of Constructions using sized types\,\citep{Gimenez98structuralrecursive}. A notable result of this work is that any well-typed term in the proposed extension is normalizing with respect to lazy evaluation, substantially widening the domain of functions to which type-based termination is applicable. In the wake of this extension, Abel\,\citep{Abel99terminationchecking} wrote a quite accessible paper on using sized types for totality checking, showing that bidirectional type checking\,\citep{Pierce00} is suitable for a system with sized types. In addition, it is described how infinite streams defined as coinductive types can be encoded in a language as functions on natural numbers, and that the productivity of a stream can be understood in terms of its \emph{definedness}, meaning the number of times it can safely be unfolded.

The notion of definedness is also an important part of Abel and Pientka's work on applying sized types to a system with copatterns\,\citep{Abel13Wellfounded}, although here it is defined more precisely as the \emph{depth} of a value of coinductive type. By directly using the notion of depth in the type system, they show that totality proofs for both coinductive definitions with copatterns and inductive definitions (as well as mixed inductive-coinductive definitions) can be constructed by well-founded induction on sizes within the type system. The method is shown to work for System F\textsubscript{$\omega$}, and has later been implemented in Agda along with copatterns.

%structurally smaller

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../copatterns-thesis"
%%% End:
